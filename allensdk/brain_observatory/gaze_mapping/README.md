# Eye tracking gaze mapping

This module takes `eye_tracking` pupil and corneal reflection (CR) ellipse
fits and uses information about the eye tracking rig geometry
(subject position, monitor position, camera position, LED position) in order
to map gaze location in terms of monitor screen coordinates.

Running the module
----
In an environment which has AllenSDK installed one can run:

`python -m allensdk.brain_observatory.gaze_mapping --help`


Eye tracking rig geometry conventions
----

1. Assumes eye is spherical (with radius of 0.1682 cm)

2. 'Eye coordinate system' (ECS) with origin (x=0, y=0, z=0) located at
    the center of the right eye.

    ECS:
    - +X: subject's right side
    - +Y: subject's anterior
    - +Z: subject's dorsal

3. Position of monitor screen center, camera lens center, and led (x, y, z)
   are expressed in terms of ECS.

   (e.g. camera position of x=130, y=0, z=0 means that camera's lens center
   is 130 cm to the right of the center of the right eye)

4. Monitor and camera have a different coordinate systems from the eye
   and are as follows for the monitor (MCS) and camera lens (CCS)
   coordinate systems.

   MCS:
   - +X: right side of screen when looking directly at screen
   - +Y: top half of screen when looking directly at screen
   - +Z: Normal to MCS XY plane and pointed directly at center of the right eye

   CCS:
   - +X: left side of camera image (right side of camera if looking toward front of camera)
   - +Y: top half of camera image
   - +Z: Normal to MCS XY plane and pointed directly at center of the right eye

5. Provided monitor 'rotations' are applied in the MCS

6. Provided camera 'rotations' are applied in the CCS

7. Eye tracking video images are presented as if looking at right eye with
   subject anterior to right of image and subject posterior to the left of
   image. (camera is actually pointed at a dichroic mirror but video frames are
   compensated [rotated 180 degrees about y-axis] prior to video upload)

General strategy
----

1. Determine where virtual image of LED is located (in ECS) by treating eye as
   a spherical convex mirror.

2. Determine the location of the pupil center in terms of ECS.
   - In CCS, calculate the delta between the pupil center and corneal reflection.
   - Find the transform that will convert from ECS -> CCS.
   - Convert the LED virtual image location determined in `1.` to CCS.
   - Using CR transformed LED virtual image as a reference point,
     apply delta to it, in order to get pupil estimates (in CCS).
   - Filter pupil estimates (remove any estimates that would result in a
     pupil location outside of eye radius).
   - Undo ECS -> CCS transform to get pupil location estimates in ECS.

3. Project a ray from origin through an estimated pupil position (`2.`) in
   order to determine the point (in ECS) at which it intersects a plane
   representing the monitor. 
   - Compute the unit normal vector for the monitor plane (in MCS)
   - Find the transform that will convert from MCS -> ECS and apply it to
     the monitor unit vector.
   - Project through estimated pupil positions to find intersection
     points with monitor plane (in ECS).

4. Transform monitor and gaze-ray intersection point (`3.`) from ECS -> MCS