
from typing import Optional

import pandas as pd
import numpy as np

from pynwb import NWBFile, ProcessingModule
from pynwb.base import TimeSeries

from allensdk.core import NwbReadableInterface
from allensdk.core import NwbWritableInterface
from allensdk.core import DataObject
from allensdk.brain_observatory.behavior.data_objects import StimulusTimestamps
from allensdk.brain_observatory.behavior.data_files import SyncFile
from allensdk.brain_observatory.behavior.data_files import (
    BehaviorStimulusFile,
    ReplayStimulusFile,
    MappingStimulusFile
)
from allensdk.brain_observatory.behavior.data_objects.running_speed.running_processing import (  # noqa: E501
    get_running_df
)

from allensdk.brain_observatory.behavior.data_objects.\
    running_speed.multi_stim_running_processing import (
        _get_multi_stim_running_df, _get_dual_stim_running_df)


class RunningAcquisition(DataObject,
                         NwbReadableInterface,
                         NwbWritableInterface):
    """A DataObject which contains properties and methods to load, process,
    and represent running acquisition data.

    Running aquisition data is represented as:

    Pandas Dataframe with an index of timestamps and the following columns:
        "dx": Angular change, computed during data collection
        "v_sig": Voltage signal from the encoder
        "v_in": The theoretical maximum voltage that the encoder
            will reach prior to "wrapping". This should
            theoretically be 5V (after crossing 5V goes to 0V, or
            vice versa). In practice the encoder does not always
            reach this value before wrapping, which can cause
            transient spikes in speed at the voltage "wraps".
    """

    def __init__(
        self,
        running_acquisition: pd.DataFrame,
        stimulus_file: Optional[BehaviorStimulusFile] = None,
        stimulus_timestamps: Optional[StimulusTimestamps] = None,
    ):
        super().__init__(name="running_acquisition", value=running_acquisition)

        if stimulus_timestamps is not None:
            if not np.isclose(stimulus_timestamps.monitor_delay, 0.0):
                raise RuntimeError(
                    "Running acquisition timestamps have montior delay "
                    f"{stimulus_timestamps.monitor_delay}; there "
                    "should be no monitor delay applied to the timestamps "
                    "associated with running acquisition")

        self._stimulus_file = stimulus_file
        self._stimulus_timestamps = stimulus_timestamps

    @classmethod
    def from_stimulus_file(
            cls,
            behavior_stimulus_file: BehaviorStimulusFile,
            sync_file: Optional[SyncFile] = None) -> "RunningAcquisition":
        """
        sync_file is used for generating timestamps. If None, timestamps
        will be generated from the stimulus file.
        """

        if sync_file is not None:
            stimulus_timestamps = StimulusTimestamps.from_sync_file(
                                        sync_file=sync_file,
                                        monitor_delay=0.0)
        else:
            stimulus_timestamps = StimulusTimestamps.from_stimulus_file(
                                        stimulus_file=behavior_stimulus_file,
                                        monitor_delay=0.0)

        running_acq_df = get_running_df(
            data=behavior_stimulus_file.data,
            time=stimulus_timestamps.value,
        )
        running_acq_df.drop("speed", axis=1, inplace=True)

        return cls(
            running_acquisition=running_acq_df,
            stimulus_file=behavior_stimulus_file,
            stimulus_timestamps=stimulus_timestamps,
        )

    @classmethod
    def from_multiple_stimulus_files(
            cls,
            behavior_stimulus_file: BehaviorStimulusFile,
            mapping_stimulus_file: MappingStimulusFile,
            replay_stimulus_file: ReplayStimulusFile,
            sync_file: SyncFile) -> "RunningAcquisition":
        """
        sync_file is used for generating timestamps.

        Stimulus blocks are assumed to be presented in the order
        behavior_stimulus_file
        mapping_stimulus_file
        replay_stimulus_file
        """

        df = _get_multi_stim_running_df(
                sync_path=sync_file.filepath,
                behavior_stimulus_file=behavior_stimulus_file,
                mapping_stimulus_file=mapping_stimulus_file,
                replay_stimulus_file=replay_stimulus_file,
                use_lowpass_filter=False,
                zscore_threshold=10.0)['running_acquisition']

        return cls(
                running_acquisition=df,
                stimulus_file=None,
                stimulus_timestamps=None)

    @classmethod
    def from_dual_stimulus_files(
            cls,
            behavior_stimulus_file: BehaviorStimulusFile,
            mapping_stimulus_file: MappingStimulusFile,
            sync_file: SyncFile) -> "RunningAcquisition":

        """
        sync_file is used for generating timestamps.

        Stimulus blocks order determined in dual stim function in multi stim running module
        """

        df = _get_dual_stim_running_df(
                sync_path=sync_file.filepath,
                behavior_stimulus_file=behavior_stimulus_file,
                mapping_stimulus_file=mapping_stimulus_file,
                use_lowpass_filter=False,
                zscore_threshold=10.0)['running_acquisition']

        return cls(
                running_acquisition=df,
                stimulus_file=None,
                stimulus_timestamps=None)

    @classmethod
    def from_nwb(
        cls,
        nwbfile: NWBFile
    ) -> "RunningAcquisition":
        running_module = nwbfile.modules['running']
        dx_interface = running_module.get_data_interface('dx')

        dx = dx_interface.data
        v_in = nwbfile.get_acquisition('v_in').data
        v_sig = nwbfile.get_acquisition('v_sig').data
        timestamps = dx_interface.timestamps[:]

        running_acq_df = pd.DataFrame(
            {
                'dx': dx,
                'v_in': v_in,
                'v_sig': v_sig
            },
            index=pd.Index(timestamps, name='timestamps')
        )
        return cls(running_acquisition=running_acq_df)

    def to_nwb(self, nwbfile: NWBFile) -> NWBFile:
        running_acquisition_df: pd.DataFrame = self.value

        running_dx_series = TimeSeries(
            name='dx',
            data=running_acquisition_df['dx'].values,
            timestamps=running_acquisition_df.index.values,
            unit='cm',
            description=(
                'Running wheel angular change, computed during data collection'
            )
        )
        v_sig = TimeSeries(
            name='v_sig',
            data=running_acquisition_df['v_sig'].values,
            timestamps=running_acquisition_df.index.values,
            unit='V',
            description='Voltage signal from the running wheel encoder'
        )
        v_in = TimeSeries(
            name='v_in',
            data=running_acquisition_df['v_in'].values,
            timestamps=running_acquisition_df.index.values,
            unit='V',
            description=(
                'The theoretical maximum voltage that the running wheel '
                'encoder will reach prior to "wrapping". This should '
                'theoretically be 5V (after crossing 5V goes to 0V, or '
                'vice versa). In practice the encoder does not always '
                'reach this value before wrapping, which can cause '
                'transient spikes in speed at the voltage "wraps".')
        )

        if 'running' in nwbfile.processing:
            running_mod = nwbfile.processing['running']
        else:
            running_mod = ProcessingModule('running',
                                           'Running speed processing module')
            nwbfile.add_processing_module(running_mod)

        running_mod.add_data_interface(running_dx_series)
        nwbfile.add_acquisition(v_sig)
        nwbfile.add_acquisition(v_in)

        return nwbfile
