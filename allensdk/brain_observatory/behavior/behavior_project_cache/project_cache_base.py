from typing import Optional, Union, List
from pathlib import Path
import logging

from allensdk.brain_observatory.behavior.behavior_project_cache.\
    project_apis.data_io import ProjectCloudApiBase
from allensdk.core.authentication import DbCredentials
from allensdk.brain_observatory.behavior.behavior_project_cache.\
    project_apis.data_io import BehaviorProjectLimsApi


class ProjectCacheBase(object):

    BUCKET_NAME: str = None
    PROJECT_NAME: str = None

    def __init__(
            self,
            fetch_api: Union[ProjectCloudApiBase, BehaviorProjectLimsApi],
            fetch_tries: int = 2,
            ):
        """
        Parameters
        ==========
        fetch_api :
            Used to pull data from remote sources, after which it is locally
            cached.
        fetch_tries :
            Maximum number of times to attempt a download before giving up and
            raising an exception. Note that this is total tries, not retries.
            Default=2.
        """

        self.fetch_api = fetch_api
        self.cache = None

        self.fetch_tries = fetch_tries
        self.logger = logging.getLogger(self.__class__.__name__)

    @property
    def manifest(self):
        if self.cache is None:
            api_name = type(self.fetch_api).__name__
            raise NotImplementedError(f"A {type(self).__name__} "
                                      f"based on {api_name} "
                                      "does not have an accessible manifest "
                                      "property")
        return self.cache.manifest

    @classmethod
    def from_s3_cache(
            cls,
            cache_dir: Union[str, Path],
            bucket_name_override: Optional[str] = None
    ) -> "ProjectCacheBase":
        """instantiates this object with a connection to an s3 bucket and/or
        a local cache related to that bucket.

        Parameters
        ----------
        cache_dir: str or pathlib.Path
            Path to the directory where data will be stored on the local system

        bucket_name_override: str
            Overrides the default bucket name for this class.
            Useful for testing
            for example, if bucket URI is 's3://mybucket' this value should be
            'mybucket'


        Returns
        -------
        ProjectCacheBase instance

        """

        fetch_api = cls.cloud_api_class().from_s3_cache(
            cache_dir,
            bucket_name=(
                bucket_name_override if bucket_name_override is not None
                else cls.BUCKET_NAME),
            project_name=cls.PROJECT_NAME,
            ui_class_name=cls.__name__)

        return cls(fetch_api=fetch_api)

    @classmethod
    def from_local_cache(
        cls,
        cache_dir: Union[str, Path],
        use_static_cache: bool = False
    ) -> "ProjectCacheBase":
        """instantiates this object with a local cache.

        Parameters
        ----------
        cache_dir: str or pathlib.Path
            Path to the directory where data will be stored on the local system

        project_name: str
            the name of the project this cache is supposed to access. This
            project name is the first part of the prefix of the release data
            objects. I.e. s3://<bucket_name>/<project_name>/<object tree>

        Returns
        -------
        ProjectCacheBase instance

        """
        fetch_api = cls.cloud_api_class().from_local_cache(
            cache_dir,
            project_name=cls.PROJECT_NAME,
            ui_class_name=cls.__name__,
            use_static_cache=use_static_cache
        )
        return cls(fetch_api=fetch_api)

    @classmethod
    def from_lims(cls, manifest: Optional[Union[str, Path]] = None,
                  version: Optional[str] = None,
                  cache: bool = False,
                  fetch_tries: int = 2,
                  lims_credentials: Optional[DbCredentials] = None,
                  mtrain_credentials: Optional[DbCredentials] = None,
                  host: Optional[str] = None,
                  scheme: Optional[str] = None,
                  asynchronous: bool = True,
                  data_release_date: Optional[Union[str, List[str]]] = None,
                  passed_only: bool = True
                  ) -> "ProjectCacheBase":
        """
        Construct a ProjectCacheBase with a lims api.

        Parameters
        ==========
        manifest : str or Path
            full path at which manifest json will be stored
        version : str
            version of manifest file. If this mismatches the version
            recorded in the file at manifest, an error will be raised.
        cache : bool
            Whether to write to the cache
        fetch_tries : int
            Maximum number of times to attempt a download before giving up and
            raising an exception. Note that this is total tries, not retries
        lims_credentials : DbCredentials
            Optional credentials to access LIMS database.
            If not set, will look for credentials in environment variables.
        mtrain_credentials: DbCredentials
            Optional credentials to access mtrain database.
            If not set, will look for credentials in environment variables.
        host : str
            Web host for the app_engine. Currently unused. This argument is
            included for consistency with EcephysProjectCache.from_lims.
        scheme : str
            URI scheme, such as "http". Currently unused. This argument is
            included for consistency with EcephysProjectCache.from_lims.
        asynchronous : bool
            Whether to fetch from web asynchronously. Currently unused.
        data_release_date: str or list of str
            Use to filter tables to only include data released on date
            ie 2021-03-25 or ['2021-03-25', '2021-08-12']
        passed_only
            Whether to limit to data with `workflow_state` set to 'passed'
            and 'published'
        Returns
        =======
        ProjectCacheBase
            ProjectCacheBase instance with a LIMS fetch API
        """
        if host and scheme:
            app_kwargs = {"host": host, "scheme": scheme,
                          "asynchronous": asynchronous}
        else:
            app_kwargs = None
        fetch_api = cls.lims_api_class().default(
            lims_credentials=lims_credentials,
            mtrain_credentials=mtrain_credentials,
            data_release_date=data_release_date,
            app_kwargs=app_kwargs,
            passed_only=passed_only
        )
        return cls(fetch_api=fetch_api, manifest=manifest, version=version,
                   cache=cache, fetch_tries=fetch_tries)

    def _cache_not_implemented(self, method_name: str) -> None:
        """
        Raise a NotImplementedError explaining that method_name
        does not exist for VisualBehaviorNeuropixelsProjectCache
        that does not have a fetch_api based on LIMS
        """
        msg = f"Method {method_name} does not exist for this "
        msg += f"{type(self).__name__}, which is based on "
        msg += f"{type(self.fetch_api).__name__}"
        raise NotImplementedError(msg)

    def construct_local_manifest(self) -> None:
        """
        Construct the local file used to determine if two files are
        duplicates of each other or not. Save it into the expected
        place in the cache. (You will see a warning if the cache
        thinks that you need to run this method).
        """
        if not isinstance(self.fetch_api, self.cloud_api_class()):
            self._cache_not_implemented('construct_local_manifest')
        self.fetch_api.cache.construct_local_manifest()

    def compare_manifests(self,
                          manifest_0_name: str,
                          manifest_1_name: str
                          ) -> str:
        """
        Compare two manifests from this dataset. Return a dict
        containing the list of metadata and data files that changed
        between them

        Note: this assumes that manifest_0 predates manifest_1

        Parameters
        ----------
        manifest_0_name: str

        manifest_1_name: str

        Returns
        -------
        str
            A string summarizing all of the changes going from
            manifest_0 to manifest_1
        """
        if not isinstance(self.fetch_api, self.cloud_api_class()):
            self._cache_not_implemented('compare_manifests')
        return self.fetch_api.cache.compare_manifests(manifest_0_name,
                                                      manifest_1_name)

    def load_latest_manifest(self) -> None:
        """
        Load the manifest corresponding to the most up to date
        version of the dataset.
        """
        if not isinstance(self.fetch_api, self.cloud_api_class()):
            self._cache_not_implemented('load_latest_manifest')
        self.fetch_api.cache.load_latest_manifest()

    def latest_downloaded_manifest_file(self) -> str:
        """
        Return the name of the most up to date data manifest
        available on your local system.
        """
        if not isinstance(self.fetch_api, self.cloud_api_class()):
            self._cache_not_implemented('latest_downloaded_manifest_file')
        return self.fetch_api.cache.latest_downloaded_manifest_file

    def latest_manifest_file(self) -> str:
        """
        Return the name of the most up to date data manifest
        corresponding to this dataset, checking in the cloud
        if this is a cloud-backed cache.
        """
        if not isinstance(self.fetch_api, self.cloud_api_class()):
            self._cache_not_implemented('latest_manifest_file')
        return self.fetch_api.cache.latest_manifest_file

    def load_manifest(self, manifest_name: str):
        """
        Load a specific versioned manifest for this dataset.

        Parameters
        ----------
        manifest_name: str
            The name of the manifest to load. Must be an element in
            self.manifest_file_names
        """
        if not isinstance(self.fetch_api, self.cloud_api_class()):
            self._cache_not_implemented('load_manifest')
        self.fetch_api.load_manifest(manifest_name)

    def list_all_downloaded_manifests(self) -> list:
        """
        Return a sorted list of the names of the manifest files
        that have been downloaded to this cache.
        """
        if not isinstance(self.fetch_api, self.cloud_api_class()):
            self._cache_not_implemented('list_all_downloaded_manifests')
        return self.fetch_api.cache.list_all_downloaded_manifests()

    def list_manifest_file_names(self) -> list:
        """
        Return a sorted list of the names of the manifest files
        associated with this dataset.
        """
        if not isinstance(self.fetch_api, self.cloud_api_class()):
            self._cache_not_implemented('list_manifest_file_names')
        return self.fetch_api.cache.manifest_file_names

    def current_manifest(self) -> Union[None, str]:
        """
        Return the name of the dataset manifest currently being
        used by this cache.
        """
        if not isinstance(self.fetch_api, self.cloud_api_class()):
            self._cache_not_implemented('current_manifest')
        return self.fetch_api.cache.current_manifest
