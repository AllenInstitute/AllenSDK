###
# This program generates a json file containing the GBM analysis run records from an sql query

# To Do: This will be done by the strategy and later removed from here.

import psycopg2
import json
import sys


def main(analysis_records_json_location, db_host, db_port, db_name, db_user, db_passwd):

    conn = psycopg2.connect(host=db_host, port=db_port, dbname=db_name, user=db_user, password=db_passwd)
    cur = conn.cursor()
    cur.execute("select distinct rna.id as rna_well_id, gen.storage_directory || gen.filename, trans.storage_directory "
                "|| trans.filename from wells rna join rs_tubes t on t.sample_id = rna.id join rna_seq_experiments e "
                "on e.rs_tube_id = t.id join rna_seq_analysis_runs_rna_seq_experiments ar2e on ar2e.rna_seq_experiment_id "
                "= e.id join well_known_files gen on gen.attachable_id = ar2e.rna_seq_analysis_run_id and "
                "gen.well_known_file_type_id = 267380639 join well_known_files trans on trans.attachable_id "
                "= ar2e.rna_seq_analysis_run_id and trans.well_known_file_type_id = 267380638 where gen.published_at is "
                "not null and gen.storage_directory ilike '%/gbm/%' order by rna.id;")
    data = cur.fetchall()
    analysis_run_records = {"analysis_run_records": []}
    for item in data:
        record = {"rna_well_id": item[0], "analysis_run_gene_path": item[1], "analysis_run_transcript_path": item[2]}
        analysis_run_records["analysis_run_records"].append(record)
    with open(analysis_records_json_location, 'w') as outfile:
        json.dump(analysis_run_records, outfile)


if __name__ == '__main__':

    analysis_records_json_location = sys.argv[1]
    db_host = sys.argv[2]
    db_port = sys.argv[3]
    db_name = sys.argv[4]
    db_user = sys.argv[5]
    db_passwd = sys.argv[6]
    main(analysis_records_json_location, db_host, db_port, db_name, db_user, db_passwd)
